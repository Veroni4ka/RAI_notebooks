{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7941148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "azure_ai_project = os.environ.get(\"AZURE_PROJECT_ENDPOINT\")\n",
    "azure_openai_deployment = os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "azure_openai_endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_api_key = os.environ.get(\"AZURE_OPENAI_API_KEY\")  \n",
    "azure_openai_api_version = os.environ.get(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "# Function to create model-specific configuration\n",
    "def get_model_config(model_name):\n",
    "\n",
    "    api_key = azure_openai_api_key\n",
    "    \n",
    "    if model_name == \"grok\":\n",
    "        return {\n",
    "            \"azure_endpoint\": azure_openai_endpoint,\n",
    "            \"azure_deployment\": \"grok-4\",\n",
    "            \"api_key\": api_key,\n",
    "            \"api_version\": \"2024-05-01-preview\",\n",
    "        }\n",
    "    elif model_name == \"gpt5\":\n",
    "        return {\n",
    "            \"azure_endpoint\": azure_openai_endpoint,\n",
    "            \"azure_deployment\": \"gpt-5-pro\",\n",
    "            \"api_key\": api_key,\n",
    "            \"api_version\": \"2024-12-01-preview\",\n",
    "        }\n",
    "    elif model_name == \"claude\":\n",
    "        return {\n",
    "            \"azure_endpoint\": azure_openai_endpoint,\n",
    "            \"azure_deployment\": \"claude-sonnet-4-5\",\n",
    "            \"api_key\": api_key,\n",
    "            \"api_version\": \"20250929\",\n",
    "        }\n",
    "    else:\n",
    "        # Default configuration from environment variables\n",
    "        api_version = azure_openai_api_version\n",
    "        if api_version and api_version < \"2024-12-01-preview\":\n",
    "            api_version = \"2024-12-01-preview\"\n",
    "        \n",
    "        return {\n",
    "            \"azure_endpoint\": azure_openai_endpoint,\n",
    "            \"azure_deployment\": azure_openai_deployment,\n",
    "            \"api_key\": azure_openai_api_key,\n",
    "            \"api_version\": api_version,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c497a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure Credential imports\n",
    "from azure.identity import AzureCliCredential\n",
    "\n",
    "!az login\n",
    "\n",
    "# Initialize Azure credentials\n",
    "credential = AzureCliCredential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbe3680",
   "metadata": {},
   "source": [
    "Setup GPT-5-pro model if you want to evaluate only that one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9254fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "azure_ai_project = os.environ.get(\"AZURE_PROJECT_ENDPOINT\")\n",
    "azure_openai_deployment = os.environ.get(\"AZURE_OPENAI_DEPLOYMENT_GPT5_PRO\")\n",
    "azure_openai_endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT_GPT5_PRO\")\n",
    "azure_openai_api_key = os.environ.get(\"AZURE_OPENAI_API_KEY_GPT5_PRO\")  \n",
    "azure_openai_api_version = os.environ.get(\"AZURE_OPENAI_API_VERSION_GPT5_PRO\")\n",
    "\n",
    "model_config = {\n",
    "    \"azure_endpoint\": azure_openai_endpoint,\n",
    "    \"azure_deployment\": azure_openai_deployment,\n",
    "    \"api_key\": azure_openai_api_key,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06ed125",
   "metadata": {},
   "source": [
    "Get all ground trut to a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cf40fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "\n",
    "path = str(pathlib.Path(pathlib.Path.cwd())) + \"/data/hiking_data.jsonl\"\n",
    "\n",
    "# Load the dataset content from the local file\n",
    "with open(path, \"r\") as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "ground_truth = [item[\"ground_truth\"] for item in data]\n",
    "print(f\"Loaded {len(ground_truth)} ground truth values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d5639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient \n",
    "\n",
    "# Create the project client (Foundry project and credentials): \n",
    "\n",
    "project_client = AIProjectClient( \n",
    "    endpoint=azure_ai_project, \n",
    "    credential=credential, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5469573b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from openai.types.evals.create_eval_jsonl_run_data_source_param import (\n",
    "    CreateEvalJSONLRunDataSourceParam,\n",
    "    SourceFileID,\n",
    ")\n",
    "from azure.ai.projects.models import (\n",
    "    DatasetVersion,\n",
    ")\n",
    "\n",
    "print(\"Creating an OpenAI client from the AI Project client\")\n",
    "client = project_client.get_openai_client()\n",
    "\n",
    "#dataset: DatasetVersion = project_client.datasets.upload_file(\n",
    "#    name=\"software_engineering_data\",\n",
    "#    version=1,\n",
    "#    file_path=path,\n",
    "#)\n",
    "#print(dataset)\n",
    "#dataset: DatasetVersion = project_client.datasets.get(\n",
    "#    name=\"software_engineering_data\",\n",
    "#    version=1,\n",
    "#)\n",
    "\n",
    "# Load the dataset content from the local file\n",
    "with open(path, \"r\") as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "conversation = client.conversations.create(\n",
    "        items=[{\"type\": \"system\", \"role\": \"system\", \"content\": \"You are an expert in hiking and know all about outdoor activities. Keep your responses brief and to the point.\"}] + \n",
    "                   [{\"type\": \"message\", \"role\": \"user\", \"content\": item[\"query\"]} for item in data],\n",
    ")\n",
    "print(f\"Created conversation with {len(data)} user messages (id: {conversation.id})\")\n",
    "\n",
    "response = client.responses.create(\n",
    "    conversation=conversation.id,\n",
    "    model=azure_openai_deployment,\n",
    "    input=\"\",\n",
    ")\n",
    "print(f\"Response output: {response.output_text} (id: {response.id})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84ae789",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_criteria = [\n",
    "            {\n",
    "                \"type\": \"azure_ai_evaluator\", \n",
    "                \"name\": \"violence_detection\", \n",
    "                \"evaluator_name\": \"builtin.violence\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"azure_ai_evaluator\",\n",
    "                \"name\": \"self_harm\",\n",
    "                \"evaluator_name\": \"builtin.self_harm\",\n",
    "                \"evaluator_version\": \"1\",\n",
    "            },\n",
    "            {\"type\": \"azure_ai_evaluator\", \"name\": \"Sexual\", \"evaluator_name\": \"builtin.sexual\", \"evaluator_version\": \"1\"},\n",
    "            {\n",
    "                \"type\": \"azure_ai_evaluator\",\n",
    "                \"name\": \"Hate Unfairness\",\n",
    "                \"evaluator_name\": \"builtin.hate_unfairness\",\n",
    "                \"evaluator_version\": \"1\",\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"azure_ai_evaluator\",\n",
    "                \"name\": \"coherence\",\n",
    "                \"evaluator_name\": \"builtin.coherence\",\n",
    "                \"initialization_parameters\": {\n",
    "                    \"deployment_name\": f\"{azure_openai_deployment}\"\n",
    "                },\n",
    "            },\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d38169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "#data_source = {\n",
    "#        \"type\": \"azure_ai_target_completions\",\n",
    "#        \"source\": {\n",
    "#            \"type\": \"file_content\",\n",
    "#            \"content\": json.dumps(dataset.as_dict()),\n",
    "#        },\n",
    "#        \"input_messages\": {\n",
    "#            \"type\": \"template\",\n",
    "#            \"template\": [\n",
    "#                {\"type\": \"message\", \"role\": \"user\", \"content\": {\"type\": \"input_text\", \"text\": \"{{item.query}}\"}}\n",
    "#            ],\n",
    "#        },\n",
    "#        \"target\": {\n",
    "#            \"type\": \"azure_ai_model\",\n",
    "#            \"model\": azure_openai_deployment,\n",
    "#        },\n",
    "#    }\n",
    "data_source_config = {\"type\": \"azure_ai_source\", \"scenario\": \"responses\"}\n",
    "data_source = {\n",
    "        \"type\": \"azure_ai_responses\",\n",
    "        \"item_generation_params\": {\n",
    "            \"type\": \"response_retrieval\",\n",
    "            \"data_mapping\": {\"response_id\": \"{{item.response}}\"},\n",
    "            \"source\": {\"type\": \"file_content\", \"content\": [{\"item\": {\"response\": response.id, \"ground_truth\": gt}} for response, gt in zip([response]*len(ground_truth), ground_truth)]},\n",
    "        },\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "eval_object = client.evals.create(\n",
    "    name=\"vk-2255-eval\",\n",
    "    data_source_config=data_source_config,\n",
    "    testing_criteria=evaluation_criteria,\n",
    ")\n",
    "results = client.evals.runs.create(\n",
    "    eval_id=eval_object.id,\n",
    "    name=\"eval_id_run\" + azure_openai_deployment + datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\"),\n",
    "    data_source=data_source,\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698fda45",
   "metadata": {},
   "source": [
    "Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682dface",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import random\n",
    "\n",
    "from azure.ai.evaluation import evaluate\n",
    "from azure.ai.evaluation import (\n",
    "    RelevanceEvaluator,\n",
    "    CoherenceEvaluator,\n",
    "    GroundednessEvaluator,\n",
    "    #QAEvaluator,\n",
    "    #F1ScoreEvaluator,\n",
    "    FluencyEvaluator,\n",
    ")\n",
    "from model_endpoints import ModelEndpoints\n",
    "\n",
    "models = [\n",
    "    \"grok\",\n",
    "    \"gpt5\",\n",
    "    \"claude\",\n",
    "]\n",
    "\n",
    "# Define a simple answer length evaluator\n",
    "def answer_length(response, **kwargs):\n",
    "    return {\"answer_length\": len(response)}\n",
    "\n",
    "path = str(pathlib.Path(pathlib.Path.cwd())) + \"/data/software_engineering_data.jsonl\"\n",
    "\n",
    "for model in models:\n",
    "    # Get model-specific configuration\n",
    "    model_config = get_model_config(model)\n",
    "    \n",
    "    randomNum = random.randint(1111, 9999)\n",
    "    \n",
    "    # Create evaluators with model-specific configuration\n",
    "    relevance_evaluator = RelevanceEvaluator(model_config, is_reasoning_model=True)\n",
    "    coherence_evaluator = CoherenceEvaluator(model_config, is_reasoning_model=True)\n",
    "    groundedness_eval = GroundednessEvaluator(model_config=model_config, is_reasoning_model=True)\n",
    "    #f1_eval = F1ScoreEvaluator(threshold=0.6)\n",
    "    #qa_eval = QAEvaluator(model_config=model_config, is_reasoning_model=True)\n",
    "    fluency_eval = FluencyEvaluator(model_config=model_config, is_reasoning_model=True)\n",
    "    \n",
    "    print(f\"Running evaluation for model: {model}\")\n",
    "    evaluation_name = \"Eval-Run-\" + str(randomNum) + \"-\" + model.title()\n",
    "    results = evaluate(\n",
    "        evaluation_name=evaluation_name,\n",
    "        data=path,\n",
    "        target=ModelEndpoints(model),\n",
    "        evaluators={\n",
    "            \"coherence\": coherence_evaluator,\n",
    "            \"relevance\": relevance_evaluator,\n",
    "            #\"groundedness\": groundedness_eval,\n",
    "            \"answer_length\": answer_length,\n",
    "            #\"qa\": qa_eval,\n",
    "            #\"f1-score\": f1_eval,\n",
    "            \"fluency\": fluency_eval\n",
    "        },\n",
    "        azure_ai_project=azure_ai_project,\n",
    "        evaluator_config={\n",
    "            \"relevance\": {\n",
    "                \"column_mapping\": {\n",
    "                    \"response\": \"${target.response}\",\n",
    "                    \"context\": \"${data.context}\",\n",
    "                    \"query\": \"${data.query}\",\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "        output_path=\"./software_engineering-\" + evaluation_name + \".json\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
