{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c497a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure Credential imports\n",
    "from azure.identity import AzureCliCredential\n",
    "\n",
    "!az login\n",
    "\n",
    "# Initialize Azure credentials\n",
    "credential = AzureCliCredential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbe3680",
   "metadata": {},
   "source": [
    "Connect to Microsoft AI Foundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9254fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "azure_ai_project = os.environ.get(\"AZURE_PROJECT_ENDPOINT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d5639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient \n",
    "\n",
    "# Create the project client (Foundry project and credentials): \n",
    "\n",
    "project_client = AIProjectClient( \n",
    "    endpoint=azure_ai_project, \n",
    "    credential=credential, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5469573b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from openai.types.evals.create_eval_jsonl_run_data_source_param import (\n",
    "    CreateEvalJSONLRunDataSourceParam,\n",
    "    SourceFileID,\n",
    ")\n",
    "from azure.ai.projects.models import (\n",
    "    DatasetVersion,\n",
    ")\n",
    "import pathlib\n",
    "\n",
    "path = str(pathlib.Path(pathlib.Path.cwd())) + \"/data.jsonl\"\n",
    "\n",
    "print(\"Creating an OpenAI client from the AI Project client\")\n",
    "client = project_client.get_openai_client()\n",
    "\n",
    "dataset: DatasetVersion = project_client.datasets.upload_file(\n",
    "    name=\"eval_data\",\n",
    "    version=1,\n",
    "    file_path=path,\n",
    ")\n",
    "#print(dataset)\n",
    "#dataset: DatasetVersion = project_client.datasets.get(\n",
    "#    name=\"eval_data\",\n",
    "#    version=1,\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84ae789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.eval_create_params import DataSourceConfigCustom\n",
    "\n",
    "evaluation_criteria = [\n",
    "            {\n",
    "            \"type\": \"azure_ai_evaluator\",\n",
    "            \"name\": \"Similarity\",\n",
    "            \"evaluator_name\": \"builtin.similarity\",\n",
    "            \"data_mapping\": {\"response\": \"{{item.response}}\", \"ground_truth\": \"{{item.ground_truth}}\"},\n",
    "            \"initialization_parameters\": {\"deployment_name\": \"gpt-5\", \"threshold\": 3},\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"azure_ai_evaluator\",\n",
    "            \"name\": \"ROUGEScore\",\n",
    "            \"evaluator_name\": \"builtin.rouge_score\",\n",
    "            \"data_mapping\": {\"response\": \"{{item.response}}\", \"ground_truth\": \"{{item.ground_truth}}\"},\n",
    "            \"initialization_parameters\": {\n",
    "                \"rouge_type\": \"rouge1\",\n",
    "                \"f1_score_threshold\": 0.5,\n",
    "                \"precision_threshold\": 0.5,\n",
    "                \"recall_threshold\": 0.5,\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"azure_ai_evaluator\",\n",
    "            \"name\": \"METEORScore\",\n",
    "            \"evaluator_name\": \"builtin.meteor_score\",\n",
    "            \"data_mapping\": {\"response\": \"{{item.response}}\", \"ground_truth\": \"{{item.ground_truth}}\"},\n",
    "            \"initialization_parameters\": {\"threshold\": 0.5},\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"azure_ai_evaluator\",\n",
    "            \"name\": \"F1Score\",\n",
    "            \"evaluator_name\": \"builtin.f1_score\",\n",
    "            \"data_mapping\": {\"response\": \"{{item.response}}\", \"ground_truth\": \"{{item.ground_truth}}\"},\n",
    "            \"initialization_parameters\": {\"threshold\": 0.5},\n",
    "        },\n",
    "]\n",
    "data_source_config = DataSourceConfigCustom(\n",
    "        {\n",
    "            \"type\": \"custom\",\n",
    "            \"item_schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\"type\": \"string\"},\n",
    "                    \"response\": {\"type\": \"string\"},\n",
    "                    \"context\": {\"type\": \"string\"},\n",
    "                    \"ground_truth\": {\"type\": \"string\"},\n",
    "                },\n",
    "                \"required\": [],\n",
    "            },\n",
    "            \"include_sample_schema\": True,\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da713d80",
   "metadata": {},
   "source": [
    "Dataset evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50bbcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "print(\"Creating evaluation\")\n",
    "eval_object = client.evals.create(\n",
    "        name=\"dataset_eval_\" + datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\"),\n",
    "        data_source_config=data_source_config,\n",
    "        testing_criteria=evaluation_criteria,  # type: ignore\n",
    ")\n",
    "print(f\"Evaluation created (id: {eval_object.id}, name: {eval_object.name})\")\n",
    "\n",
    "\n",
    "print(\"Creating evaluation run with Dataset ID\")\n",
    "eval_run_object = client.evals.runs.create(\n",
    "    eval_id=eval_object.id,\n",
    "    name=\"dataset_id_run\",\n",
    "    metadata={\"team\": \"eval-exp\", \"scenario\": \"dataset-id-v1\"},\n",
    "    data_source=CreateEvalJSONLRunDataSourceParam(\n",
    "         type=\"jsonl\", source=SourceFileID(type=\"file_id\", id=dataset.id if dataset.id else \"\")\n",
    "    ),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
